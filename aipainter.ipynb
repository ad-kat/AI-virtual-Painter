{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47deea85-5a10-4d87-87f7-27d7b1189471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f51e5dee-4c54-40a0-b25b-a2c4f9a8daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_shape=(480,640,3)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles=mp.solutions.drawing_styles\n",
    "mphands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728917ce-2b68-4faf-a6ba-e187a44b5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trace Handusing Hands()\n",
    "#tracking index finger using mediapipe\n",
    "cap=cv2.VideoCapture(0)\n",
    "hands = mphands.Hands()\n",
    "while True:\n",
    "    data,image = cap.read()\n",
    "    image = cv2.cvtColor(cv2.flip(image,1), cv2.COLOR_BGRA2BGR) #flip image\n",
    "    results=hands.process(image)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGRA2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image,\n",
    "                                      hand_landmarks,\n",
    "                                      mphands.HAND_CONNECTIONS)\n",
    "            #index finger location for drawing stuff\n",
    "            x=hand_landmarks.landmark[8].x*frame_shape[1]\n",
    "            y=hand_landmarks.landmark[8].y*frame_shape[0]\n",
    "            x=int(x)\n",
    "            y=int(y)\n",
    "    cv2.imshow('Handtracker',image)\n",
    "    if cv2.waitKey(1)==27 | 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af810773-b932-42ac-966d-b0d96cca37fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m data,image \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     12\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mflip(image,\u001b[38;5;241m1\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGRA2BGR) \u001b[38;5;66;03m#flip image\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m results\u001b[38;5;241m=\u001b[39m\u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m image\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcvtColor(image,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGRA2BGR)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:372\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    366\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    368\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    369\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    370\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#draw a line\n",
    "mask=np.zeros(frame_shape,dtype='uint8')\n",
    "color=(125,100,140)\n",
    "thickness=4\n",
    "cap=cv2.VideoCapture(0)\n",
    "hands = mphands.Hands()\n",
    "prevxy=None\n",
    "\n",
    "\n",
    "while True:\n",
    "    data,image = cap.read()\n",
    "    image = cv2.cvtColor(cv2.flip(image,1), cv2.COLOR_BGRA2BGR) #flip image\n",
    "    results=hands.process(image)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image,\n",
    "                                      hand_landmarks,\n",
    "                                      mphands.HAND_CONNECTIONS)\n",
    "            #index finger location for drawing stuff\n",
    "            x=hand_landmarks.landmark[8].x*frame_shape[1]\n",
    "            y=hand_landmarks.landmark[8].y*frame_shape[0]\n",
    "            x=int(x)\n",
    "            y=int(y)\n",
    "            if prevxy!=None:\n",
    "                cv2.line(mask,prevxy,(x,y),color,thickness)\n",
    "            prevxy=(x,y)\n",
    "    \n",
    "    image=np.where(mask,mask,image)\n",
    "    cv2.imshow('Handtracker',image)    \n",
    "    if cv2.waitKey(1)==27 | 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daddd2d6-d647-43a4-8ca1-c25e7781b811",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_int(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[0;32m    114\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 98\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m cTime \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     97\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m detector \u001b[38;5;241m=\u001b[39m \u001b[43mhandDetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m, in \u001b[0;36mhandDetector.__init__\u001b[1;34m(self, mode, maxHands, detectionCon, trackCon)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrackCon \u001b[38;5;241m=\u001b[39m trackCon\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpHands \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mhands\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhands \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmpHands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHands\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxHands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectionCon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrackCon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpDraw \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_utils\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtipIds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m20\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:114\u001b[0m, in \u001b[0;36mHands.__init__\u001b[1;34m(self, static_image_mode, max_num_hands, model_complexity, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m              static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     91\u001b[0m              max_num_hands\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     92\u001b[0m              model_complexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     93\u001b[0m              min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     94\u001b[0m              min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a MediaPipe Hand object.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m      https://solutions.mediapipe.dev/hands#min_tracking_confidence.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbinary_graph_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_BINARYPB_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m      \u001b[49m\u001b[43mside_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_complexity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_complexity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_hands\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_hands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_prev_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstatic_image_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcalculator_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpalmdetectioncpu__TensorsToDetectionsCalculator.min_score_thresh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhandlandmarkcpu__ThresholdingCalculator.threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_hand_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_hand_world_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_handedness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m    130\u001b[0m \u001b[43m      \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:296\u001b[0m, in \u001b[0;36mSolutionBase.__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    294\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mobserve_output_stream(stream_name, callback, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_side_packets \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_side_input_type_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mside_inputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mstart_run(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_side_packets)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:297\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    294\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mobserve_output_stream(stream_name, callback, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_side_packets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 297\u001b[0m     name: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_side_input_type_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, data \u001b[38;5;129;01min\u001b[39;00m (side_inputs \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    299\u001b[0m }\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mstart_run(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_side_packets)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:599\u001b[0m, in \u001b[0;36mSolutionBase._make_packet\u001b[1;34m(self, packet_data_type, data)\u001b[0m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(packet_creator, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m packet_data_type\u001b[38;5;241m.\u001b[39mvalue)(\n\u001b[0;32m    597\u001b[0m       data, image_format\u001b[38;5;241m=\u001b[39mimage_frame\u001b[38;5;241m.\u001b[39mImageFormat\u001b[38;5;241m.\u001b[39mSRGB)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpacket_data_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: create_int(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: int) -> mediapipe.python._framework_bindings.packet.Packet\n\nInvoked with: 0.5"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class handDetector():\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5):\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands,\n",
    "        self.detectionCon, self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "def findHands(self, img, draw=True):\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    self.results = self.hands.process(imgRGB)\n",
    "    # print(results.multi_hand_landmarks)\n",
    "\n",
    "    if self.results.multi_hand_landmarks:\n",
    "        for handLms in self.results.multi_hand_landmarks:\n",
    "            if draw:\n",
    "                self.mpDraw.draw_landmarks(img, handLms,\n",
    "                self.mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    return img\n",
    "\n",
    "def findPosition(self, img, handNo=0, draw=True):\n",
    "    xList = []\n",
    "    yList = []\n",
    "    bbox = []\n",
    "    self.lmList = []\n",
    "    if self.results.multi_hand_landmarks:\n",
    "        myHand = self.results.multi_hand_landmarks[handNo]\n",
    "        for id, lm in enumerate(myHand.landmark):\n",
    "            # print(id, lm)\n",
    "            h, w, c = img.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            xList.append(cx)\n",
    "            yList.append(cy)\n",
    "            # print(id, cx, cy)\n",
    "            self.lmList.append([id, cx, cy])\n",
    "            if draw:\n",
    "                cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "    xmin, xmax = min(xList), max(xList)\n",
    "    ymin, ymax = min(yList), max(yList)\n",
    "    bbox = xmin, ymin, xmax, ymax\n",
    "\n",
    "    if draw:\n",
    "        cv2.rectangle(img, (xmin - 20, ymin - 20), (xmax + 20, ymax + 20),\n",
    "        (0, 255, 0), 2)\n",
    "\n",
    "    return self.lmList, bbox\n",
    "\n",
    "def fingersUp(self):\n",
    "    fingers = []\n",
    "    # Thumb\n",
    "    if self.lmList[self.tipIds[0]][1] > self.lmList[self.tipIds[0] - 1][1]:\n",
    "        fingers.append(1)\n",
    "    else:\n",
    "        fingers.append(0)\n",
    "\n",
    "    # Fingers\n",
    "    for id in range(1, 5):\n",
    "        if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "        # totalFingers = fingers.count(1)\n",
    "\n",
    "    return fingers\n",
    "\n",
    "def findDistance(self, p1, p2, img, draw=True,r=15, t=3):\n",
    "    x1, y1 = self.lmList[p1][1:]\n",
    "    x2, y2 = self.lmList[p2][1:]\n",
    "    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "    if draw:\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), t)\n",
    "        cv2.circle(img, (x1, y1), r, (255, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(img, (x2, y2), r, (255, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(img, (cx, cy), r, (0, 0, 255), cv2.FILLED)\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "    return length, img, [x1, y1, x2, y2, cx, cy]\n",
    "\n",
    "def main():\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    detector = handDetector()\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = detector.findHands(img)\n",
    "        lmList, bbox = detector.findPosition(img)\n",
    "        if len(lmList) != 0:\n",
    "            print(lmList[4])\n",
    "\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "        (255, 0, 255), 3)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1961b7d-6c24-40ce-bd7f-a5d1fadb3a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (340,955,3) into shape (50,250,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m _, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      9\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, \u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m---> 11\u001b[0m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_col\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_col\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m tools\n\u001b[0;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLive\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (340,955,3) into shape (50,250,3)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc155b1-6485-4b6b-bd02-80fbcf4299e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
